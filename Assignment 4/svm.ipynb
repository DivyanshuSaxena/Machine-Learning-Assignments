{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_images = np.load('transformed.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"./train_dataset/\"\n",
    "tree = sorted(list(os.walk(rootdir)))\n",
    "\n",
    "rewards = []\n",
    "for root, sub_folders, files in tree:\n",
    "        print (root)\n",
    "        if len(files) != 0:\n",
    "            reward_file = os.path.join(root, 'rew.csv')\n",
    "            episode_reward = np.genfromtxt(reward_file)\n",
    "            episode_reward = np.append(episode_reward, 0.0)\n",
    "            rewards.append(episode_reward)\n",
    "rewards = np.array(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the training, test and validation data\n",
    "train_data = []\n",
    "train_output = []\n",
    "test_data = []\n",
    "test_output = []\n",
    "validation_data = []\n",
    "validation_output = []\n",
    "\n",
    "iteration_index = list(range(len(transformed_images)))\n",
    "random.shuffle(iteration_index)\n",
    "\n",
    "num0 = 0\n",
    "num1 = 0\n",
    "\n",
    "for e_index in iteration_index:\n",
    "    print (e_index)\n",
    "    episode = transformed_images[e_index]\n",
    "    episode_rewards = rewards[e_index]\n",
    "    for f_index in range(6, len(episode)):\n",
    "        reward = episode_rewards[f_index]\n",
    "        if reward == 0:\n",
    "            # Generate only one example for a sample with reward zero\n",
    "            num0 += 1\n",
    "            frame_indexes = np.sort(np.random.choice(6, 4, replace=False))\n",
    "            frame = []\n",
    "            for index in frame_indexes:\n",
    "                frame.append(episode[f_index-6+index])\n",
    "            frame.append(episode[f_index])\n",
    "            frame = np.array(frame).flatten()\n",
    "            prob = np.random.uniform()\n",
    "            if prob < 0.2:\n",
    "                validation_data.append(frame)\n",
    "                validation_output.append(reward)\n",
    "            elif prob < 0.5:\n",
    "                test_data.append(frame)\n",
    "                test_output.append(reward)\n",
    "            else:\n",
    "                train_data.append(frame)\n",
    "                train_output.append(reward)\n",
    "        else:\n",
    "            # Generate all possible examples\n",
    "            num1 += 1\n",
    "            indexes = np.arange(6)\n",
    "            combinations = list(itertools.combinations(indexes, 4))\n",
    "            sample_reward = np.ones(len(combinations))\n",
    "            sample_data = []\n",
    "            for frame_indexes in combinations:\n",
    "                frame = []\n",
    "                for index in frame_indexes:\n",
    "                    frame.append(episode[f_index-6+index])\n",
    "                frame.append(episode[f_index])\n",
    "                frame = np.array(frame).flatten()\n",
    "                sample_data.append(frame)\n",
    "            prob = np.random.uniform()\n",
    "            if prob < 0.2:\n",
    "                validation_data.extend(sample_data)\n",
    "                validation_output.extend(sample_reward)\n",
    "            elif prob < 0.5:\n",
    "                test_data.extend(sample_data)\n",
    "                test_output.extend(sample_reward)\n",
    "            else:\n",
    "                train_data.extend(sample_data)\n",
    "                train_output.extend(sample_reward)\n",
    "                \n",
    "train_data = np.array(train_data)\n",
    "train_output = np.array(train_output)\n",
    "test_data = np.array(test_data)\n",
    "test_output = np.array(test_output)\n",
    "validation_data = np.array(validation_data)\n",
    "validation_output = np.array(validation_output)\n",
    "print (train_data.shape)\n",
    "print (test_data.shape)\n",
    "print (validation_data.shape)\n",
    "print (num0, num1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data files\n",
    "np.save('./dataset/train.data', train_data)\n",
    "np.save('./dataset/train.output', train_output)\n",
    "np.save('./dataset/test.data', test_data)\n",
    "np.save('./dataset/test.output', test_output)\n",
    "np.save('./dataset/val.data', validation_data)\n",
    "np.save('./dataset/val.output', validation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "train_data = np.load('./dataset/train.data.npy')\n",
    "train_output = np.load('./dataset/train.output.npy')\n",
    "test_data = np.load('./dataset/test.data.npy')\n",
    "test_output = np.load('./dataset/test.output.npy')\n",
    "validation_data = np.load('./dataset/val.data.npy')\n",
    "validation_output = np.load('./dataset/val.output.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_data, axis=0)\n",
    "std = np.std(train_data, axis=0)\n",
    "normalized_train = (train_data - mean) / std\n",
    "normalized_test = (test_data - mean) / std\n",
    "normalized_val = (validation_data - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 10000\n",
    "model_linear = SVC(kernel='linear', class_weight='balanced', verbose=True, tol=0.00001*num_examples, max_iter=10000)\n",
    "%time model_linear.fit(normalized_train[0:num_examples], train_output[0:num_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_examples = 10000\n",
    "predictions = model_linear.predict(normalized_val[0:num_val_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(validation_output[0:num_val_examples], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear.score(normalized_test, test_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
