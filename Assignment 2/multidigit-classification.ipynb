{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "import svmutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cvxopt import matrix\n",
    "from cvxopt import solvers\n",
    "from cvxopt.solvers import qp\n",
    "\n",
    "# Hyperparameters\n",
    "gamma = 0.05\n",
    "gaussian = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for PART A\n",
    "train_data_raw = np.genfromtxt('./ass2_data/digit_train.csv', delimiter=',')\n",
    "test_data_raw = np.genfromtxt('./ass2_data/digit_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data and divide into arrays\n",
    "scale_down = lambda x : x/255\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for i in range(10):\n",
    "    train_data.append([])\n",
    "    test_data.append([])\n",
    "\n",
    "for sample in train_data_raw:\n",
    "    y = int(sample[-1])\n",
    "    insert_sample = list(map(scale_down, sample[:-1]))\n",
    "    insert_sample.append(sample[-1])\n",
    "    train_data[y].append(insert_sample)\n",
    "    \n",
    "for sample in test_data_raw:\n",
    "    y = int(sample[-1])\n",
    "    insert_sample = list(map(scale_down, sample[:-1]))\n",
    "    insert_sample.append(sample[-1])\n",
    "    test_data[y].append(insert_sample)\n",
    "    \n",
    "solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(digit1, digit2):\n",
    "    get_class = lambda x : 1 if x == digit1 else -1\n",
    "\n",
    "    partial_data = np.concatenate((train_data[digit1], train_data[digit2]), axis=0)\n",
    "    m = len(partial_data)\n",
    "    alphas = np.array([])\n",
    "    w = np.array([])\n",
    "    b = 0\n",
    "\n",
    "    # Get input for the solver\n",
    "    X = np.delete(partial_data, -1, axis=1)\n",
    "    if not gaussian:\n",
    "        Y = np.diag([get_class(y) for y in partial_data[:, -1]])\n",
    "        kernel = np.matmul(X, X.T)\n",
    "        temp_P = np.matmul(np.matmul(Y, kernel), Y)\n",
    "        P = matrix(temp_P)\n",
    "    else:\n",
    "        Y = np.diag([get_class(y) for y in partial_data[:, -1]])\n",
    "        xtx = np.sum(np.multiply(X, X), 1).reshape(m, 1)\n",
    "        kernel_noexp = xtx + xtx.T - 2 * np.dot(X, X.T)\n",
    "        kernel = np.power(np.exp(-1*gamma), kernel_noexp)\n",
    "        temp_P = np.matmul(np.matmul(Y, kernel), Y)\n",
    "        P = matrix(temp_P)\n",
    "\n",
    "    q = matrix(1.0, (m,1))\n",
    "\n",
    "    G = matrix(np.identity(m))\n",
    "    G_identity = np.identity(m)\n",
    "    temp_G = np.concatenate((G_identity, -G_identity), axis=0)\n",
    "    G = matrix(temp_G)\n",
    "\n",
    "    h = matrix(0.0, (m,1))\n",
    "    h_zero = np.zeros(m)\n",
    "    h_ones = np.ones(m)\n",
    "    temp_h = np.append(h_zero, h_ones)\n",
    "    h = matrix(temp_h, (2*m,1))\n",
    "\n",
    "    temp_A = list(map(get_class, partial_data[0:m, -1]))\n",
    "    A = matrix(np.array(temp_A), (1, m), 'd')\n",
    "\n",
    "    b = matrix(0.0)\n",
    "\n",
    "    # Use the cvxopt solver qp module\n",
    "    alphas = qp(P, q, G, h, A, b)['x']\n",
    "    alphas = np.array(-alphas)[:, 0]\n",
    "    print (alphas)\n",
    "    \n",
    "    # Evaluate w if linear kernel used\n",
    "    if not gaussian:\n",
    "        w = np.zeros(28*28)\n",
    "        for i in range(m):\n",
    "            sample = partial_data[i]\n",
    "            w += alphas[i] * get_class(sample[-1]) * sample[:-1]\n",
    "\n",
    "    # Evaluate b\n",
    "    alpha_y = np.multiply(alphas, np.array(list(map(get_class, partial_data[:, -1]))) )\n",
    "    print (alpha_y.shape)\n",
    "\n",
    "    w_trans_X = np.matmul(kernel, alpha_y)\n",
    "    maxone = -99999999\n",
    "    minone = 99999999\n",
    "    for i in range(m):\n",
    "        wtx = w_trans_X[i]\n",
    "        y = get_class(partial_data[i][-1])\n",
    "        if y == -1:\n",
    "            maxone = max(maxone, wtx)\n",
    "        else:\n",
    "            minone = min(minone, wtx)\n",
    "\n",
    "    b = -(maxone + minone)/2\n",
    "    print (b)\n",
    "    \n",
    "    return alpha_y, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = []\n",
    "alpha_y = []\n",
    "partial_data = []\n",
    "X = []\n",
    "XtX = []\n",
    "Y = []\n",
    "b = np.zeros(shape=(10, 10))\n",
    "lengths = []\n",
    "for i in range(10):\n",
    "    row_w = []\n",
    "    row_alpha = []\n",
    "    row_data = []\n",
    "    row_x = []\n",
    "    row_y = []\n",
    "    row_lengths = []\n",
    "    row_xtx = []\n",
    "    for j in range(10):\n",
    "        row_w.append(np.array([]))\n",
    "        row_alpha.append(np.array([]))\n",
    "        row_data.append(np.array([]))\n",
    "        row_x.append(np.array([]))\n",
    "        row_y.append(np.array([]))\n",
    "        row_xtx.append(np.array([]))\n",
    "        row_lengths.append(0)\n",
    "    w.append(row_w)\n",
    "    alpha_y.append(row_alpha)\n",
    "    partial_data.append(row_data)\n",
    "    X.append(row_x)\n",
    "    Y.append(row_y)\n",
    "    lengths.append(row_lengths)\n",
    "    XtX.append(row_xtx)\n",
    "\n",
    "get_class = lambda x, digit : 1 if x == digit else -1\n",
    "    \n",
    "# Collate Partial Data\n",
    "for digit1 in range(0, 9):\n",
    "    for digit2 in range(digit1+1, 10):\n",
    "        partial_data[digit1][digit2] = np.concatenate((train_data[digit1], train_data[digit2]), axis=0)\n",
    "        X[digit1][digit2] = np.delete(partial_data[digit1][digit2], -1, axis=1)                \n",
    "        Y[digit1][digit2] = np.diag([get_class(y, digit1) for y in partial_data[digit1][digit2][:, -1]])\n",
    "        lengths[digit1][digit2] = len(partial_data[digit1][digit2])\n",
    "        XtX[digit1][digit2] = np.sum(np.multiply(X[digit1][digit2], X[digit1][digit2]), 1).reshape(lengths[digit1][digit2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the classifiers for each pair of digits\n",
    "def get_parameters_from_file():\n",
    "    try:\n",
    "        with open('ass2_data/parameters.txt') as f: \n",
    "            parameters = [x.rstrip() for x in f.readlines()]\n",
    "            counter = 0\n",
    "            for digit1 in range(9):\n",
    "                for digit2 in range(digit1+1, 10):\n",
    "                    alpha_y[digit1][digit2] = np.fromstring(parameters[counter], dtype=float, sep=',')\n",
    "                    b[digit1][digit2] = float(parameters[counter+1])\n",
    "                    counter += 2\n",
    "    except FileNotFoundError:\n",
    "        for digit1 in range(10):\n",
    "            for digit2 in range(digit1+1, 10):\n",
    "                t = get_parameters(digit1, digit2)\n",
    "                alpha_y[digit1][digit2], w[digit1][digit2], b[digit1][digit2] = t[0], t[1], t[2]\n",
    "                print (\"Done for {0}, {1}\".format(digit1, digit2))\n",
    "                w[digit2][digit1] = w[digit1][digit2]\n",
    "                b[digit2][digit1] = b[digit1][digit2]\n",
    "        # Write into file\n",
    "        parameters_text = open('ass2_data/parameters.txt', 'w')\n",
    "        for digit1 in range(9):\n",
    "            for digit2 in range(digit1+1, 10):\n",
    "                alpha_str = ', '.join(\"{0:.10f}\".format(x) for x in alpha_y[digit1][digit2]) # '0,3,5'\n",
    "                parameters_text.write(alpha_str)\n",
    "                parameters_text.write(\"\\n{0}\\n\".format(b[digit1][digit2]))\n",
    "        parameters_text.close()\n",
    "\n",
    "get_parameters_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collated_test = np.array([])\n",
    "collated_train = np.array([])\n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        collated_test = test_data[i]\n",
    "        collated_train = train_data[i]\n",
    "    else:\n",
    "        collated_test = np.concatenate((collated_test, test_data[i]), axis=0)\n",
    "        collated_train = np.concatenate((collated_train, train_data[i]), axis=0)\n",
    "\n",
    "test_m = len(collated_test)\n",
    "train_m = len(collated_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(data, length):\n",
    "    accuracy = counter = 0\n",
    "    confusion_matrix = np.zeros(shape=(10,10))\n",
    "    for sample in data[0:1000]:\n",
    "        counts = [(0,0)] * 10\n",
    "        counter += 1\n",
    "        xtx = np.sum(np.multiply(sample[:-1], sample[:-1])).reshape(1,1)\n",
    "        for digit1 in range(0, 9):\n",
    "            for digit2 in range(digit1+1, 10):\n",
    "                b_local = b[digit1][digit2]\n",
    "                if not gaussian:\n",
    "                    w_local = w[digit1][digit2]\n",
    "                    pred_z = np.dot(w_local.T, sample[:-1]) + b_local\n",
    "                else:\n",
    "                    inner_product = xtx + XtX[digit1][digit2].T - 2 * np.dot(sample[:-1], X[digit1][digit2].T)\n",
    "                    wtx = np.dot(alpha_y[digit1][digit2], np.power(np.exp(-gamma), inner_product.T))\n",
    "                    pred_z = wtx + b_local\n",
    "\n",
    "                if pred_z > 0:\n",
    "                    counts[digit1] = (counts[digit1][0]+1, counts[digit1][1]+pred_z)\n",
    "                    # print(\"Predicting {0} among {0},{1}\".format(digit1, digit2))\n",
    "                else:\n",
    "                    counts[digit2] = (counts[digit2][0]+1, counts[digit2][1]-pred_z)\n",
    "                    # print(\"Predicting {1} among {0},{1}\".format(digit1, digit2))\n",
    "        index = max(enumerate(counts), key=lambda x: 1000*x[1][0]+x[1][1])[0]\n",
    "        # print ([x[0] for x in counts], index)\n",
    "        if index == sample[-1]:\n",
    "            accuracy += 1\n",
    "\n",
    "        # Evaluate confusion matrix for PART C\n",
    "        confusion_matrix[index][int(sample[-1])] += 1\n",
    "        ten_percent = 10*length/100\n",
    "        if counter%length == 0:\n",
    "            print (\"Completed {0}0% with accuracy {1}\".format(counter/ten_percent, accuracy/counter))\n",
    "    print (\"Accuracy: \".format(accuracy/length * 100))\n",
    "    \n",
    "    # Print confusion matrix for PART C\n",
    "    np.set_printoptions(suppress=True)\n",
    "    print (confusion_matrix)\n",
    "\n",
    "print (\"For Train Data: \", end='')\n",
    "get_accuracy(collated_train, train_m)\n",
    "print (\"For Test Data: \", end='')\n",
    "get_accuracy(collated_test, test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = collated_train[:, -1]\n",
    "X = np.delete(collated_train, -1, axis=1)\n",
    "\n",
    "start_time = time.time()\n",
    "m_gaussian = svmutil.svm_train(Y, X, \"-t 2 -c 1 -g 0.05\")\n",
    "print (\"Time taken by LibSVM for training Gaussian Kernels: {0}\".format(time.time()-start_time))\n",
    "\n",
    "Y_test = collated_test[:, -1]\n",
    "X_test = np.delete(collated_test, -1, axis=1)\n",
    "\n",
    "print (\"For Train Set: \", end='')\n",
    "labels_gaussian = svmutil.svm_predict(Y, X, m_gaussian)\n",
    "print (\"For Test Set: \", end='')\n",
    "labels_gaussian = svmutil.svm_predict(Y_test, X_test, m_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Validation for PART D\n",
    "validation_data = np.array([])\n",
    "train_validate_data = np.array([])\n",
    "for i in range(10):\n",
    "    length = len(train_data[i])\n",
    "    validation_index = int(length/10)\n",
    "    if i == 0:\n",
    "        validation_data = train_data[i][0:validation_index]\n",
    "        train_validate_data = train_data[i][validation_index:]\n",
    "    else:\n",
    "        validation_data = np.concatenate((validation_data, train_data[i][0:validation_index]), axis=0)\n",
    "        train_validate_data = np.concatenate((train_validate_data, train_data[i][validation_index:]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.00001, 0.001, 1, 5, 10]\n",
    "\n",
    "Y_tv = train_validate_data[:, -1]\n",
    "X_tv = np.delete(train_validate_data, -1, axis=1)\n",
    "Y_validate = validation_data[:, -1]\n",
    "X_validate = np.delete(validation_data, -1, axis=1)\n",
    "\n",
    "validation_acc = []\n",
    "test_acc = []\n",
    "\n",
    "for c in C:\n",
    "    m = svmutil.svm_train(Y_tv, X_tv, \"-t 2 -c {0} -g 0.05\".format(c))\n",
    "    p_label, p_acc, p_val = svmutil.svm_predict(Y_validate, X_validate, m)\n",
    "    p_label_t, p_acc_t, p_val_t = svmutil.svm_predict(Y_test, X_test, m)\n",
    "    validation_acc.append(p_acc[0])    \n",
    "    test_acc.append(p_acc_t[0])\n",
    "\n",
    "print (validation_acc, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(C, validation_acc, 'r-')\n",
    "plt.plot(C, test_acc, 'b-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
