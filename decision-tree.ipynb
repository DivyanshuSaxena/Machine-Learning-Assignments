{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediate_data(array):\n",
    "    median = np.median(array)\n",
    "    preprocess = lambda x : 0 if x < median else 1\n",
    "    return np.array([preprocess(xi) for xi in array])\n",
    "\n",
    "def get_values(array):\n",
    "    unique_values = np.unique(array)\n",
    "    if 7 in unique_values:\n",
    "        unique_values = np.array(range(-2, 10))\n",
    "    return unique_values\n",
    "\n",
    "def calculate_entropy(array):\n",
    "    entropy = 0\n",
    "    for x_tuple in array:\n",
    "        x_samples = sum(x_tuple)\n",
    "        x_entropy = 0\n",
    "        for y_samples in x_tuple:\n",
    "            x_entropy += (-y_samples*math.log(y_samples/x_samples))\n",
    "        entropy += x_samples*x_entropy\n",
    "    return entropy\n",
    "\n",
    "class Node:\n",
    "    children = []\n",
    "    attribute = -1\n",
    "    sample_indexes = []\n",
    "    sample_class = 0\n",
    "    is_leaf = 1\n",
    "    \n",
    "    def __init__(self, index_list):\n",
    "        self.sample_indexes = index_list\n",
    "        self.children = []\n",
    "        self.attribute = -1\n",
    "        self.sample_class = 0\n",
    "        self.is_leaf = 1\n",
    "    \n",
    "root = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "train_raw = np.genfromtxt('./ass3_data/credit-cards.train.csv', delimiter=',', skip_header=2)\n",
    "test_raw = np.genfromtxt('./ass3_data/credit-cards.test.csv', delimiter=',', skip_header=2)\n",
    "val_raw = np.genfromtxt('./ass3_data/credit-cards.val.csv', delimiter=',', skip_header=2)\n",
    "\n",
    "train_continuous = train_raw[:, [1,2,5,12,13,14,15,16,17,18,19,20,21,22,23]]\n",
    "test_continuous = test_raw[:, [1,2,5,12,13,14,15,16,17,18,19,20,21,22,23]]\n",
    "val_continuous = val_raw[:, [1,2,5,12,13,14,15,16,17,18,19,20,21,22,23]]\n",
    "train_category = train_raw[:, [3,4,6,7,8,9,10,11]]\n",
    "test_category = test_raw[:, [3,4,6,7,8,9,10,11]]\n",
    "val_category = val_raw[:, [3,4,6,7,8,9,10,11]]\n",
    "\n",
    "train_output = train_raw[:, -1]\n",
    "test_output = test_raw[:, -1]\n",
    "val_output = val_raw[:, -1]\n",
    "\n",
    "train_cont_data = np.apply_along_axis(mediate_data, 0, train_continuous)\n",
    "test_cont_data = np.apply_along_axis(mediate_data, 0, test_continuous)\n",
    "val_cont_data = np.apply_along_axis(mediate_data, 0, val_continuous)\n",
    "\n",
    "train_data = np.concatenate((train_category, train_cont_data), axis=1)\n",
    "test_data = np.concatenate((test_category, test_cont_data), axis=1)\n",
    "val_data = np.concatenate((val_category, val_cont_data), axis=1)\n",
    "\n",
    "attribute_values = {i: get_values(train_data.T[i]) for i in range(len(train_data.T))}\n",
    "\n",
    "num_attributes = len(train_data[0])\n",
    "print (attribute_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part A\n",
    "m = len(train_data)\n",
    "# m = 5000\n",
    "root = Node(list(range(m)))\n",
    "epsilon = 0.05\n",
    "path_attr = []\n",
    "\n",
    "def grow_tree(curr):\n",
    "    # print (\"Starting for node with indexes: {0}\".format(curr.sample_indexes)) # Debug\n",
    "    count_y = []\n",
    "    for X in attribute_values:\n",
    "        values = attribute_values[X]\n",
    "        temp_y = [] \n",
    "        for i in range(len(values)):\n",
    "            temp_y.append([epsilon, epsilon])\n",
    "        count_y.append(temp_y)\n",
    "\n",
    "    # Compute y values\n",
    "    samples0 = samples1 = 0\n",
    "    for index in curr.sample_indexes:\n",
    "        y = int(train_output[index])\n",
    "        if y == 0:\n",
    "            samples0 += 1\n",
    "        else:\n",
    "            samples1 += 1\n",
    "        for feature_index in range(num_attributes):\n",
    "            attribute = int(train_data[index][feature_index])\n",
    "            if feature_index in range(2,8):\n",
    "                attribute += 2\n",
    "            count_y[feature_index][attribute][y] += 1\n",
    "    # print (\"For the current node, samples0: {0} and samples1: {1}\".format(samples0, samples1))\n",
    "    if samples0 < 1 or samples1 < 1:\n",
    "        curr.sample_class = 1 if samples1 > samples0 else 0\n",
    "        # print (\"Giving class {0} for current node\".format(curr.sample_class)) # Debug\n",
    "        return 0\n",
    "\n",
    "    # Compute entropies of each attribute and choose the best attribute\n",
    "    best_attribute = -1\n",
    "    best_entropy = 0\n",
    "    found_attribute = False\n",
    "    for X in attribute_values:\n",
    "        entropy = calculate_entropy(count_y[X])\n",
    "        if (entropy < best_entropy or best_attribute == -1) and X not in path_attr:\n",
    "            found_attribute = True\n",
    "            best_attribute = X\n",
    "            best_entropy = entropy\n",
    "            \n",
    "    if not found_attribute:\n",
    "        # print (\"Exiting because no suitable attribute found\")\n",
    "        curr.sample_class = 1 if samples1 > samples0 else 0\n",
    "        # print (\"Giving class {0} for current node\".format(curr.sample_class)) # Debug\n",
    "        return 0\n",
    "    # print (\"Split at attribute {0}\".format(best_attribute, count_y[best_attribute])) # Debug\n",
    "    curr.attribute = best_attribute\n",
    "    path_attr.append(best_attribute)\n",
    "\n",
    "    # Make children and append them to the children array\n",
    "    children_indexes = []\n",
    "    for i in attribute_values[best_attribute]:\n",
    "        children_indexes.append([])\n",
    "    for index in curr.sample_indexes:\n",
    "        attribute = int(train_data[index][best_attribute])\n",
    "        if best_attribute in range(2,8):\n",
    "            attribute += 2\n",
    "        children_indexes[attribute].append(index)\n",
    "    for x in attribute_values[best_attribute]:\n",
    "        if best_attribute in range(2,8):\n",
    "            x += 2\n",
    "        child = Node(children_indexes[int(x)])\n",
    "        curr.children.append(child)\n",
    "        \n",
    "    # Recursively grow tree on the children nodes\n",
    "    for child in curr.children:\n",
    "        if len(child.sample_indexes) > 0:\n",
    "            curr.is_leaf = 0\n",
    "            grow_tree(child)\n",
    "            \n",
    "    path_attr.remove(best_attribute)\n",
    "    # print (path_attr)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grow_tree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Accuracy functions\n",
    "def get_classification(sample, curr):\n",
    "    # Go to the child based on current best attribute\n",
    "    # print (\"Starting for node with attribute: {0}, class: {1}, children: {3} and values: {2}\"\n",
    "    #       .format(curr.attribute, curr.sample_class, attribute_values[curr.attribute], len(curr.children))) # Debug\n",
    "    if curr.is_leaf == 1:\n",
    "        return curr.sample_class\n",
    "    sample_attribute = sample[curr.attribute]\n",
    "    if curr.attribute in range(2,8):\n",
    "        sample_attribute += 2\n",
    "    return get_classification(sample, curr.children[int(sample_attribute)])\n",
    "    \n",
    "def get_accuracy(dataset, dataset_output):\n",
    "    accuracy = 0\n",
    "    for index in range(len(dataset)):\n",
    "        sample = dataset[index]\n",
    "        model_class = get_classification(sample, root)\n",
    "        if model_class == dataset_output[index]:\n",
    "            accuracy += 1\n",
    "    print (accuracy/len(dataset)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Training Accuracy\n",
    "get_accuracy(train_data[0:m], train_output[0:m])\n",
    "get_accuracy(test_data, test_output)\n",
    "get_accuracy(val_data, val_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
